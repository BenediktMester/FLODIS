{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Socio-economic indicators preprocessing\n",
    "Prepare all spatial-explicit socio-economic indicators to be linked with the flood disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os.path\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from contextlib import contextmanager  \n",
    "import rasterio\n",
    "from rasterio import Affine\n",
    "from rasterio.enums import Resampling\n",
    "import numpy as np\n",
    "import rasterio \n",
    "from osgeo import gdal\n",
    "from osgeo import ogr\n",
    "from osgeo import gdalconst\n",
    "import gdal\n",
    "import xarray as xr\n",
    "\n",
    "# Create paths\n",
    "local_path = os.getcwd() + '/'\n",
    "\n",
    "def mkdir(dir):\n",
    "    \n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "        \n",
    "data_path = local_path + 'data/'\n",
    "data_processed_path = local_path + 'data_processed/'\n",
    "socio_economic_variables_path = data_processed_path + 'socio_economic_variables/'\n",
    "socio_economic_variables_path_creator = mkdir(socio_economic_variables_path)\n",
    "forest_data_path = socio_economic_variables_path + 'forest/'\n",
    "forest_data_path_creator = mkdir(forest_data_path)\n",
    "forest_path = socio_economic_variables_path + 'forest/'\n",
    "forest_path_creator = mkdir(forest_path)\n",
    "urbanization_path = socio_economic_variables_path + 'urbanization/'\n",
    "urbanization_path_creator = mkdir(urbanization_path)\n",
    "landuse_path = socio_economic_variables_path + 'landuse/'\n",
    "landuse_path_creator = mkdir(landuse_path)\n",
    "FLOPROS_path = socio_economic_variables_path + 'FLOPROS/'\n",
    "FLOPROS_path_creator = mkdir(FLOPROS_path)\n",
    "HDI_path = socio_economic_variables_path + 'HDI/'\n",
    "HDI_path_creator = mkdir(HDI_path)\n",
    "GDP_path = socio_economic_variables_path + 'GDP/'\n",
    "GDP_path_creator = mkdir(GDP_path)\n",
    "GDPpc_path = socio_economic_variables_path + 'GDPpc/'\n",
    "GDPpc_path_creator = mkdir(GDPpc_path)\n",
    "female_path = socio_economic_variables_path + 'female/'\n",
    "female_path_creator = mkdir(female_path)\n",
    "age_path = socio_economic_variables_path + 'age/' # Used in other script\n",
    "age_path_creator = mkdir(age_path)\n",
    "demo_path = socio_economic_variables_path + 'demographic/' # Used in other script\n",
    "demo_path_creator = mkdir(demo_path)\n",
    "\n",
    "crs = {'init' :'epsg:4326'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global forest cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest cover tiles need to be first downloaded from \"https://glad.umd.edu/Potapov/TCC_2010/treecover2010/\".\n",
    "# Start downloading data\n",
    "for lat in ['N','S']:\n",
    "    \n",
    "    for long in ['E','W']:\n",
    "   \n",
    "        for lat_deg in range(0,8+1):\n",
    "        \n",
    "            for long_deg in range(0,17+1):\n",
    "                \n",
    "                if long_deg <10:\n",
    "                    long_deg = '0'+str(long_deg)\n",
    "\n",
    "                url = f\"https://glad.umd.edu/Potapov/TCC_2010/treecover2010/treecover2010_{lat_deg}0{lat}_{long_deg}0{long}.tif\"\n",
    "                tif_name = url.rsplit('/', 1)[1]\n",
    "               \n",
    "                print(tif_name)\n",
    "                    \n",
    "                if os.path.isfile(forest_data_path + tif_name):\n",
    "                    print (\"File exist\")\n",
    "                else:\n",
    "                    print (\"File not exist\")\n",
    "  \n",
    "                    r = requests.get(url, allow_redirects=True)\n",
    "                    tif_name=url.rsplit('/', 1)[1]\n",
    "                    open(forest_data_path+tif_name, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample from 30 m to 300 m to reduce the file size\n",
    "for lat in ['N','S']:\n",
    "    \n",
    "    for long in ['E','W']:\n",
    "   \n",
    "        for lat_deg in range(0,8+1):\n",
    "        \n",
    "            for long_deg in range(0,17+1):\n",
    "                \n",
    "                if long_deg <10:\n",
    "                    long_deg = '0'+str(long_deg)\n",
    "\n",
    "                url = f\"https://glad.umd.edu/Potapov/TCC_2010/treecover2010_{lat_deg}0{lat}_{long_deg}0{long}.tif\"\n",
    "                tif_name = url.rsplit('/', 1)[1]\n",
    "                \n",
    "                print(tif_name)\n",
    "                \n",
    "                if os.path.isfile(forest_path + 'resampled_' + tif_name):\n",
    "                    print (\"File exists\")\n",
    "                else:\n",
    "                    print (\"File not exists\")\n",
    "                    \n",
    "                    try:\n",
    "                        observed_flooding = path_forests + tif_name\n",
    "                        raster = gdal.Open(observed_flooding)\n",
    "                        gt =raster.GetGeoTransform()\n",
    "                        pixelSizeX_satellite = gt[1]\n",
    "                        pixelSizeY_satellite =-gt[5]\n",
    "                        satellite_cropped_resampled_1 = forest_path + 'resampled_' + tif_name\n",
    "                        pixel_transformerX_satellite = 1/10\n",
    "                        pixel_transformerY_satellite = 1/10\n",
    "\n",
    "                        @contextmanager\n",
    "                        def resample_raster(raster, scaleX, scaleY):\n",
    "                            t = raster.transform\n",
    "\n",
    "                            # rescale the metadata\n",
    "                            transform = Affine(t.a / scaleX, t.b, t.c, t.d, t.e / scaleY, t.f)\n",
    "                            height = raster.height * scaleY\n",
    "                            width = raster.width * scaleX\n",
    "\n",
    "                            profile = src.profile\n",
    "                            profile.update(transform=transform, driver='GTiff', height=height, width=width, crs=crs)\n",
    "\n",
    "                            data = raster.read( # Note changed order of indexes, arrays are band, row, col order not row, col, band\n",
    "                                    out_shape=(int(raster.count), int(height), int(width)),\n",
    "                                    resampling=Resampling.average)\n",
    "\n",
    "                            data = np.float32(data)\n",
    "                            profile['dtype'] = 'float32'\n",
    "\n",
    "                            with rasterio.open((satellite_cropped_resampled_1),'w', **profile) as dst:\n",
    "                                dst.write(data)\n",
    "                                yield data\n",
    "\n",
    "                        # Apply Function by defining scaling factor        \n",
    "\n",
    "                        with rasterio.open(observed_flooding) as src:\n",
    "                            with resample_raster(src, pixel_transformerX_satellite, pixel_transformerY_satellite) as resampled: \n",
    "                                print('Sat Orig dims: {}, New dims: {}'.format(src.shape, resampled.shape)) \n",
    "                              \n",
    "                    except:\n",
    "\n",
    "                        print('...but sea!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLOPROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLOPROS data is provided on a province (state) level, this section 'burns' the flood protection information on a grid\n",
    "# Prepare grid with 0s.\n",
    "rst_fn = rasterio.open(data_path + 'templates/grid_blank.tif')\n",
    "raster_profile = rst_fn.profile\n",
    "raster_profile['count'] = 1\n",
    "raster_profile['dtype'] = 'float32'\n",
    "rst_fn = np.squeeze(rst_fn.read())\n",
    "rst_fn[rst_fn != 777] = 0\n",
    "\n",
    "with rasterio.open(data_path + 'grid_blank_0.tif', 'w', **raster_profile) as dst:\n",
    "    dst.write_band(1, rst_fn)   \n",
    "    \n",
    "#This raster is the model for our output (CRS, extent)\n",
    "ndsm = data_path + 'grid_blank_0.tif'\n",
    "\n",
    "#This shapefile contains the features we want to burn\n",
    "shp = data_path + 'FLOPROS_shp_V1/FLOPROS_shp_V1.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burn shape into raster - MERGED FLOPROS\n",
    "data = gdal.Open(ndsm, gdalconst.GA_ReadOnly)\n",
    "geo_transform = data.GetGeoTransform()\n",
    "x_min = geo_transform[0]\n",
    "y_max = geo_transform[3]\n",
    "x_max = x_min + geo_transform[1] * data.RasterXSize\n",
    "y_min = y_max + geo_transform[5] * data.RasterYSize\n",
    "x_res = data.RasterXSize\n",
    "y_res = data.RasterYSize\n",
    "vec = ogr.Open(shp)\n",
    "lyr = vec.GetLayer(0)\n",
    "pixel_width = geo_transform[1]\n",
    "\n",
    "output = FLOPROS_path + 'FLOPROS_merged.tif'\n",
    "target_ds = gdal.GetDriverByName('GTiff').Create(output, x_res, y_res, 1, gdal.GDT_UInt32)\n",
    "target_ds.SetGeoTransform((x_min, pixel_width, 0, y_min, 0, pixel_width))\n",
    "band = target_ds.GetRasterBand(1)\n",
    "NoData_value = 0\n",
    "band.SetNoDataValue(NoData_value)\n",
    "band.FlushCache()\n",
    "\n",
    "driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "for feat in lyr:\n",
    "    burn_value = feat.GetField(\"MerL_Riv\")\n",
    "    datasource = driver.CreateDataSource(FLOPROS_path + 'temp.shp')\n",
    "    layer = datasource.CreateLayer('temp', lyr.GetSpatialRef(), geom_type=ogr.wkbPolygon)\n",
    "    layer.CreateFeature(feat)\n",
    "    gdal.RasterizeLayer(target_ds, [1], layer, burn_values=[burn_value])\n",
    "    datasource.Destroy()\n",
    "\n",
    "#This makes raster to write to disk\n",
    "target_ds = None    \n",
    "raster_fn = np.squeeze(rasterio.open(FLOPROS_path + 'FLOPROS_merged.tif').read())\n",
    "raster_fn = np.float32(raster_fn)\n",
    "raster_fn = np.fliplr(np.flip(raster_fn))\n",
    "\n",
    "with rasterio.open(FLOPROS_path + 'FLOPROS_merged.tif', 'w', **raster_profile) as dst:\n",
    "    dst.write_band(1, raster_fn)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burn shape into raster - MODELED FLOPROS\n",
    "data = gdal.Open(ndsm, gdalconst.GA_ReadOnly)\n",
    "geo_transform = data.GetGeoTransform()\n",
    "x_min = geo_transform[0]\n",
    "y_max = geo_transform[3]\n",
    "x_max = x_min + geo_transform[1] * data.RasterXSize\n",
    "y_min = y_max + geo_transform[5] * data.RasterYSize\n",
    "x_res = data.RasterXSize\n",
    "y_res = data.RasterYSize\n",
    "vec = ogr.Open(shp)\n",
    "lyr = vec.GetLayer(0)\n",
    "pixel_width = geo_transform[1]\n",
    "\n",
    "output = FLOPROS_path + 'FLOPROS_modeled.tif'\n",
    "target_ds = gdal.GetDriverByName('GTiff').Create(output, x_res, y_res, 1, gdal.GDT_UInt32)\n",
    "target_ds.SetGeoTransform((x_min, pixel_width, 0, y_min, 0, pixel_width))\n",
    "band = target_ds.GetRasterBand(1)\n",
    "NoData_value = 0\n",
    "band.SetNoDataValue(NoData_value)\n",
    "band.FlushCache()\n",
    "\n",
    "driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "for feat in lyr:\n",
    "    burn_value = feat.GetField(\"ModL_Riv\")\n",
    "    datasource = driver.CreateDataSource(FLOPROS_path + 'temp.shp')\n",
    "    layer = datasource.CreateLayer('temp', lyr.GetSpatialRef(), geom_type=ogr.wkbPolygon)\n",
    "    layer.CreateFeature(feat)\n",
    "    gdal.RasterizeLayer(target_ds, [1], layer, burn_values=[burn_value])\n",
    "    datasource.Destroy()\n",
    "\n",
    "#This makes raster to write to disk\n",
    "target_ds = None    \n",
    "raster_fn = np.squeeze(rasterio.open(FLOPROS_path + 'FLOPROS_modeled.tif').read())\n",
    "raster_fn = np.float32(raster_fn)\n",
    "raster_fn = np.fliplr(np.flip(raster_fn))\n",
    "\n",
    "with rasterio.open(FLOPROS_path + 'FLOPROS_modeled.tif', 'w', **raster_profile) as dst:\n",
    "    dst.write_band(1, raster_fn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urbanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year bands from .nc and save as .tif\n",
    "urb = rasterio.open('netcdf:' +  data_path + 'socio_economic_variables/urbanization/landuse-urbanareas_histsoc_annual_1901_2019.nc')\n",
    "urb_profile = urb.profile\n",
    "urb_profile['driver'] = 'GTiff'\n",
    "urb_profile['count'] = 1\n",
    "urb_profile['dtype'] = 'float32'\n",
    "urb_profile['crs'] = crs \n",
    "\n",
    "for year,year_val in zip(range(1901,2019),range(1,119)):\n",
    "    \n",
    "    if year >= 2000:    \n",
    "        urb_temp = urb.read(year_val).astype(np.float32) \n",
    "\n",
    "        with rasterio.open(urbanization_path + f\"urbanization_{year}.tif\", 'w', **urb_profile) as dst:\n",
    "            dst.write_band(1, urb_temp)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year bands from .nc and save as .tif\n",
    "landuse = rasterio.open('netcdf:' +  data_path + 'socio_economic_variables/landuse/landuse-totals_histsoc_annual_1901_2019.nc')\n",
    "landuse_profile = landuse.profile\n",
    "landuse_profile['driver'] = 'GTiff'\n",
    "landuse_profile['count'] = 1\n",
    "landuse_profile['dtype'] = 'float32'\n",
    "landuse_profile['crs'] = crs \n",
    "\n",
    "landuse = xr.open_dataset(data_path + 'socio_economic_variables/landuse/landuse-totals_histsoc_annual_1901_2019.nc',decode_times = False)\n",
    "\n",
    "for year,year_val in zip(range(1901,2019),range(1,119)):\n",
    "    \n",
    "    if year >= 2000:   \n",
    "        landuse_temp = landuse.cropland_total[year_val].values \n",
    "\n",
    "        with rasterio.open(landuse_path + f\"landuse_{year}.tif\", 'w', **landuse_profile) as dst:\n",
    "            dst.write_band(1, landuse_temp)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year bands from .nc and save as .tif\n",
    "HDI = rasterio.open('netcdf:' +  data_path + 'socio_economic_variables/HDI/HDI_1990_2015_v2.nc')\n",
    "HDI_profile = HDI.profile\n",
    "HDI_profile['driver'] = 'GTiff'\n",
    "HDI_profile['count'] = 1\n",
    "HDI_profile['dtype'] = 'float32'\n",
    "HDI_profile['crs'] = crs \n",
    "\n",
    "for year,year_val in zip(range(1990,2016),range(1,27)):\n",
    "    \n",
    "    if year >= 2000:    \n",
    "        HDI_temp = HDI.read(year_val).astype(np.float32) \n",
    "\n",
    "        with rasterio.open(HDI_path + f\"HDI_{year}.tif\", 'w', **HDI_profile) as dst:\n",
    "            dst.write_band(1, HDI_temp)  \n",
    "            \n",
    "# Extrapolation of missing years\n",
    "HDI_2000 = rasterio.open(HDI_path + f\"HDI_2000.tif\")\n",
    "HDI_2015 = rasterio.open(HDI_path + f\"HDI_2015.tif\")\n",
    "HDI_profile = HDI_2015.profile\n",
    "HDI_2000_np = np.float32(HDI_2000.read(1))\n",
    "HDI_2015_np = np.float32(HDI_2015.read(1))\n",
    "HDI_gradient = np.float32(HDI_2015_np - HDI_2000_np)/15\n",
    "   \n",
    "# 2016\n",
    "\n",
    "HDI_temp_np = np.float32(HDI_2015_np + HDI_gradient * 1)\n",
    "HDI_temp_np[HDI_temp_np > 1] = 1\n",
    "\n",
    "with rasterio.open(HDI_path + f\"HDI_2016.tif\", 'w', **HDI_profile) as dst:\n",
    "    dst.write_band(1, HDI_temp_np) \n",
    "    \n",
    "# 2017\n",
    "\n",
    "HDI_temp_np = np.float32(HDI_2015_np + HDI_gradient * 2)\n",
    "HDI_temp_np[HDI_temp_np > 1] = 1\n",
    "\n",
    "with rasterio.open(HDI_path + f\"HDI_2017.tif\", 'w', **HDI_profile) as dst:\n",
    "    dst.write_band(1, HDI_temp_np) \n",
    "    \n",
    "# 2018\n",
    "\n",
    "HDI_temp_np = np.float32(HDI_2015_np + HDI_gradient * 3)\n",
    "HDI_temp_np[HDI_temp_np > 1] = 1\n",
    "\n",
    "with rasterio.open(HDI_path + f\"HDI_2018.tif\", 'w', **HDI_profile) as dst:\n",
    "    dst.write_band(1, HDI_temp_np) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year bands from .nc and save as .tif. \n",
    "GDP = rasterio.open('netcdf:' +  data_path + 'socio_economic_variables/GDP/GDP_PPP_1990_2015_5arcmin_v2.nc')\n",
    "GDP_profile = GDP.profile\n",
    "GDP_profile['driver'] = 'GTiff'\n",
    "GDP_profile['count'] = 1\n",
    "GDP_profile['dtype'] = 'float32'\n",
    "GDP_profile['crs'] = crs \n",
    "\n",
    "for year,year_val in zip(range(1990,2016),range(1,27)):\n",
    "    \n",
    "    if year >= 2000:    \n",
    "        GDP_temp = GDP.read(year_val).astype(np.float32) \n",
    "\n",
    "        with rasterio.open(GDP_path + f\"GDP_{year}.tif\", 'w', **GDP_profile) as dst:\n",
    "            dst.write_band(1, GDP_temp)  \n",
    "            \n",
    "# Extrapolation of missing years\n",
    "GDP_2000 = rasterio.open(GDP_path + f\"GDP_2000.tif\")\n",
    "GDP_2015 = rasterio.open(GDP_path + f\"GDP_2015.tif\")\n",
    "GDP_profile = GDP_2015.profile\n",
    "GDP_2000_np = np.float32(GDP_2000.read(1))\n",
    "GDP_2015_np = np.float32(GDP_2015.read(1))\n",
    "GDP_2015_np[GDP_2015_np < 0] = np.nan\n",
    "GDP_gradient = np.float32(GDP_2015_np - GDP_2000_np)/15\n",
    "   \n",
    "# 2016\n",
    "\n",
    "GDP_temp_np = np.float32(GDP_2015_np + GDP_gradient * 1)\n",
    "GDP_temp_np[GDP_temp_np < 0] = 0\n",
    "\n",
    "with rasterio.open(GDP_path + f\"GDP_2016.tif\", 'w', **GDP_profile) as dst:\n",
    "    dst.write_band(1, GDP_temp_np) \n",
    "    \n",
    "# 2017\n",
    "\n",
    "GDP_temp_np = np.float32(GDP_2015_np + GDP_gradient * 2)\n",
    "GDP_temp_np[GDP_temp_np < 0] = 0\n",
    "\n",
    "with rasterio.open(GDP_path + f\"GDP_2017.tif\", 'w', **GDP_profile) as dst:\n",
    "    dst.write_band(1, GDP_temp_np) \n",
    "    \n",
    "# 2018\n",
    "\n",
    "GDP_temp_np = np.float32(GDP_2015_np + GDP_gradient * 3)\n",
    "GDP_temp_np[GDP_temp_np < 0] = 0\n",
    "\n",
    "with rasterio.open(GDP_path + f\"GDP_2018.tif\", 'w', **GDP_profile) as dst:\n",
    "    dst.write_band(1, GDP_temp_np) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year bands from .nc and save as .tif. \n",
    "GDPpc = rasterio.open('netcdf:' +  data_path + 'socio_economic_variables/GDPpc/GDP_per_capita_PPP_1990_2015_v2.nc')\n",
    "GDPpc_profile = GDPpc.profile\n",
    "GDPpc_profile['driver'] = 'GTiff'\n",
    "GDPpc_profile['count'] = 1\n",
    "GDPpc_profile['dtype'] = 'float32'\n",
    "GDPpc_profile['crs'] = crs \n",
    "\n",
    "for year,year_val in zip(range(1990,2016),range(1,27)):\n",
    "    \n",
    "    if year >= 2000:    \n",
    "        GDPpc_temp = GDPpc.read(year_val).astype(np.float32) \n",
    "\n",
    "        with rasterio.open(GDPpc_path + f\"GDPpc_{year}.tif\", 'w', **GDPpc_profile) as dst:\n",
    "            dst.write_band(1, GDPpc_temp)  \n",
    "            \n",
    "# Extrapolation of missing years\n",
    "GDPpc_2000 = rasterio.open(GDPpc_path + f\"GDPpc_2000.tif\")\n",
    "GDPpc_2015 = rasterio.open(GDPpc_path + f\"GDPpc_2015.tif\")\n",
    "GDPpc_profile = GDPpc_2015.profile\n",
    "GDPpc_2000_np = np.float32(GDPpc_2000.read(1))\n",
    "GDPpc_2015_np = np.float32(GDPpc_2015.read(1))\n",
    "GDPpc_2015_np[GDPpc_2015_np < 0] = np.nan\n",
    "GDPpc_gradient = np.float32(GDPpc_2015_np - GDPpc_2000_np)/15\n",
    "   \n",
    "# 2016\n",
    "\n",
    "GDPpc_temp_np = np.float32(GDPpc_2015_np + GDPpc_gradient * 1)\n",
    "GDPpc_temp_np[GDPpc_temp_np < 0] = 0\n",
    "\n",
    "with rasterio.open(GDPpc_path + f\"GDPpc_2016.tif\", 'w', **GDPpc_profile) as dst:\n",
    "    dst.write_band(1, GDPpc_temp_np) \n",
    "    \n",
    "# 2017\n",
    "\n",
    "GDPpc_temp_np = np.float32(GDPpc_2015_np + GDPpc_gradient * 2)\n",
    "GDPpc_temp_np[GDPpc_temp_np < 0] = 0\n",
    "\n",
    "with rasterio.open(GDPpc_path + f\"GDPpc_2017.tif\", 'w', **GDPpc_profile) as dst:\n",
    "    dst.write_band(1, GDPpc_temp_np) \n",
    "    \n",
    "# 2018\n",
    "\n",
    "GDPpc_temp_np = np.float32(GDPpc_2015_np + GDPpc_gradient * 3)\n",
    "GDPpc_temp_np[GDPpc_temp_np < 0] = 0\n",
    "\n",
    "with rasterio.open(GDPpc_path + f\"GDPpc_2018.tif\", 'w', **GDPpc_profile) as dst:\n",
    "    dst.write_band(1, GDPpc_temp_np) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
