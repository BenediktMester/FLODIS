{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1efc350",
   "metadata": {},
   "source": [
    "# Postprocessing\n",
    "Load matched disaster datasets, clean, and merge if matched with same GFD floods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1756eb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mester/.local/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.10.3-CAPI-1.16.1). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import glob\n",
    "          \n",
    "# Create paths\n",
    "\n",
    "def mkdir(dir):    \n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "        \n",
    "path_local = os.getcwd() + '/'\n",
    "path_data = path_local + 'data/'\n",
    "path_data_processed = path_local + 'data_processed/'\n",
    "path_FLODIS_final = path_data_processed + 'FLODIS_final/'\n",
    "path_FLODIS_final_creator = mkdir(path_FLODIS_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6767d0",
   "metadata": {},
   "source": [
    "# IDMC functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426d4702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unneccessary rows and columns. \n",
    "# Check for national vs. subnational entries.\n",
    "# Search for entries with the same GFD ID. \n",
    "\n",
    "def drop_columns_rows(df):\n",
    "    \n",
    "    df = df[df.columns.drop(df.filter(regex='Unnamed:'))]     \n",
    "    df = df.drop([\n",
    "       'event_name',\n",
    "       'Hazard Category', 'Hazard Type',\n",
    "       'country_only_info','provinces','districts',\n",
    "  #     'num_provinces', 'num_districts',\n",
    "       'start_date', 'Name',\n",
    "       'idx', \n",
    "        'countries_forUKonly'],axis=1)\n",
    "    df = df.replace(-np.inf,np.nan)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def matches_filter(df):\n",
    "    print('Number of IDMC flood events (2008-2018):',len(df))\n",
    "    df = df[df.GFD_matches > 0]\n",
    "    print('Number of succesfully matched IDMC events:',len(df),'\\n\\n')\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def nat_vs_subnat(df):\n",
    "\n",
    "    sum_columns = ['displacements',]\n",
    "\n",
    "    mean_columns = [ 'GFD_matches_time_dif', 'GFD_duration',        \n",
    "           'pop_density_GHSL', \n",
    "           'pop_density_GPW','pop_affected_mean_GHSL','pop_affected_mean_GPW','GDP_affected_mean',\n",
    "           'education_affected_mean','energy_affected_mean','health_affected_mean',\n",
    "           'telecommunication_affected_mean','transportation_affected_mean','water_affected_mean',\n",
    "           'CISI_global_affected_mean', 'cable_affected_mean',\n",
    "           'plant_affected_mean', 'power_pole_affected_mean',\n",
    "           'power_tower_affected_mean', 'line_affected_mean', 'mast_affected_mean',\n",
    "           'communication_tower_affected_mean', 'doctors_affected_mean',\n",
    "           'hospital_affected_mean', 'pharmacy_affected_mean',\n",
    "           'primary_road_affected_mean', 'tertiary_road_affected_mean',\n",
    "           'reservoir_affected_mean', 'school_affected_mean',\n",
    "           'university_affected_mean', 'GDPpc_mean', 'HDI_mean',\n",
    "           'urbanization_mean', 'landuse_total_mean', \n",
    "           'elevation_mean','roughness_mean','slope_mean','female_mean',               \n",
    "           'pop_0_14_mean', 'pop_65_plus_mean', 'FLOPROS_merged_mean',\n",
    "           'FLOPROS_modeled_mean', 'forest_cover_mean']\n",
    "\n",
    "    max_columns = ['pop_affected_sum_GHSL', \n",
    "                   'pop_affected_sum_GPW','GDP_affected_sum', 'cable_affected_sum', 'plant_affected_sum',\n",
    "                   'power_pole_affected_sum', 'power_tower_affected_sum',\n",
    "                   'line_affected_sum', 'mast_affected_sum',\n",
    "                   'communication_tower_affected_sum', 'doctors_affected_sum',\n",
    "                   'hospital_affected_sum', 'pharmacy_affected_sum',\n",
    "                   'primary_road_affected_sum', 'tertiary_road_affected_sum',\n",
    "                   'reservoir_affected_sum', 'school_affected_sum',\n",
    "                   'university_affected_sum']\n",
    "    \n",
    "    for ID in df.GFD_matches_nr.unique():\n",
    "\n",
    "        df_temp_1 = df[df['GFD_matches_nr']==ID]\n",
    "\n",
    "        for ISO3 in df_temp_1.ISO3.unique():\n",
    "\n",
    "            df_temp_2 = df_temp_1[df_temp_1.ISO3 == ISO3]\n",
    "\n",
    "            if len(df_temp_2) > 1: \n",
    "                df_nat = df_temp_2[((df_temp_2.GID_1.isnull()) & (df_temp_2.GID_2.isnull()))]\n",
    "                df_non_nat = df_temp_2.drop(df_nat.index.to_list()) \n",
    "\n",
    "                if df_nat.displacements.sum() > df_non_nat.displacements.sum():\n",
    "                    print('nat. entry > subnat. entry')\n",
    "                    print(ISO3)\n",
    "                    print(ID)\n",
    "                    ISO3_temp = df_temp_2.ISO3.iloc[0]\n",
    "                    GFD_matches_temp = df_temp_2.GFD_matches.max()\n",
    "                    GFD_matching_type_temp = 3\n",
    "                    print(df_temp_2.GFD_matches_nr)\n",
    "                    print(len(df_temp_2.GFD_matches_nr))\n",
    "                    \n",
    "                    GFD_matches_nr_temp = ID\n",
    "                    print(\"New nr:\",GFD_matches_nr_temp)\n",
    "                    GID_1_temp = ''\n",
    "                    GID_2_temp = ''\n",
    "\n",
    "                    for i in df_temp_2.GID_1:\n",
    "                        \n",
    "                        if str(i) != 'nan':\n",
    "                            GID_1_temp = GID_1_temp + str(i) + ','\n",
    "\n",
    "                    try:\n",
    "                        if GID_1_temp[-1] == ',':\n",
    "                            GID_1_temp = GID_1_temp[:-1]        \n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    for i in df_temp_2.GID_2:\n",
    "                        \n",
    "                        if str(i) != 'nan':\n",
    "                            GID_2_temp = GID_2_temp + str(i) + ','\n",
    "\n",
    "                    try:\n",
    "                        if GID_2_temp[-1] == ',':\n",
    "                            GID_2_temp = GID_2_temp[:-1]        \n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    if len(GID_1_temp) > 1:\n",
    "                        GID_1_temp_len = len(GID_1_temp.split(','))\n",
    "                        \n",
    "                    else:\n",
    "                        GID_1_temp_len = np.nan\n",
    "                        \n",
    "                    \n",
    "                    if len(GID_2_temp) > 1:\n",
    "                        GID_2_temp_len = len(GID_2_temp.split(','))\n",
    "                        \n",
    "                    else:\n",
    "                        GID_2_temp_len = np.nan\n",
    "\n",
    "                    df_max = pd.DataFrame(df_temp_2[max_columns].max()).T\n",
    "                    df_mean = pd.DataFrame(df_temp_2[mean_columns].mean()).T\n",
    "                    df_sum = pd.DataFrame(df_temp_2[sum_columns].sum()).T\n",
    "                    row_single = pd.concat([df_sum,df_max,df_mean], axis=1)\n",
    "\n",
    "                    try:\n",
    "                        row_single = row_single.drop(['GID_1'],axis=1)\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        row_single = row_single.drop(['GID_2'],axis=1)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    row_single.insert(0,'ISO3',ISO3_temp)\n",
    "                    row_single.insert(1,'GFD_matches',GFD_matches_temp)\n",
    "                    row_single.insert(2,'GFD_matches_nr',GFD_matches_nr_temp)\n",
    "                    row_single.insert(3,'matching_type',GFD_matching_type_temp)\n",
    "                    row_single.insert(4,'GID_1',GID_1_temp)\n",
    "                    row_single.insert(5,'GID_2',GID_2_temp)\n",
    "                    row_single.insert(6,'num_provinces',GID_1_temp_len)\n",
    "                    row_single.insert(7,'num_districts',GID_2_temp_len)\n",
    "                    row_single['year'] = np.round(df_temp_2.year.mean(),0)\n",
    "                    row_single = row_single.reindex(columns=df.columns)\n",
    "                    df = df.drop(df_temp_2.index.to_list())\n",
    "                    df = df.append(row_single)\n",
    "                    \n",
    "                    print(row_single.GFD_matches_nr)\n",
    "                   \n",
    "                else:\n",
    "                    print('nat. entry dropped')\n",
    "                    df = df.drop(df_nat.index.to_list())\n",
    "   \n",
    "    print('Number of succesfully matched IDMC events:',len(df))\n",
    "    print(\"Number of individual GFD events:\",len(df.GFD_matches_nr.unique()),'\\n\\n')\n",
    "    df = df.reset_index(drop=True)    \n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def province_duplicate_merger(df):\n",
    "    \n",
    "    sum_columns = ['displacements',]\n",
    "\n",
    "    mean_columns = ['GFD_matches_time_dif', 'GFD_duration',        \n",
    "                    'pop_density_GHSL', \n",
    "                    'pop_density_GPW',\n",
    "                    'pop_affected_sum_GHSL', \n",
    "                    'pop_affected_sum_GPW','GDP_affected_sum', 'cable_affected_sum', 'plant_affected_sum',\n",
    "                    'power_pole_affected_sum', 'power_tower_affected_sum',\n",
    "                    'line_affected_sum', 'mast_affected_sum',\n",
    "                    'communication_tower_affected_sum', 'doctors_affected_sum',\n",
    "                    'hospital_affected_sum', 'pharmacy_affected_sum',\n",
    "                    'primary_road_affected_sum', 'tertiary_road_affected_sum',\n",
    "                    'reservoir_affected_sum', 'school_affected_sum',\n",
    "                    'university_affected_sum',\n",
    "                    'affected_mean_GHSL','affected_mean_GPW','GDP_affected_mean',\n",
    "                    'education_affected_mean','energy_affected_mean','health_affected_mean',\n",
    "                    'telecommunication_affected_mean','transportation_affected_mean','water_affected_mean',\n",
    "                    'CISI_global_affected_mean', 'cable_affected_mean',\n",
    "                    'plant_affected_mean', 'power_pole_affected_mean',\n",
    "                    'power_tower_affected_mean', 'line_affected_mean', 'mast_affected_mean',\n",
    "                    'communication_tower_affected_mean', 'doctors_affected_mean',\n",
    "                    'hospital_affected_mean', 'pharmacy_affected_mean',\n",
    "                    'primary_road_affected_mean', 'tertiary_road_affected_mean',\n",
    "                    'reservoir_affected_mean', 'school_affected_mean',\n",
    "                    'university_affected_mean', 'GDPpc_mean', 'HDI_mean',\n",
    "                    'urbanization_mean', 'landuse_total_mean', 'elevation_mean','roughness_mean',\n",
    "                    'slope_mean','female_mean',               \n",
    "                    'pop_0_14_mean', 'pop_65_plus_mean', 'FLOPROS_merged_mean',\n",
    "                    'FLOPROS_modeled_mean', 'forest_cover_mean']\n",
    "\n",
    "    max_columns = []\n",
    "\n",
    "    for ID in df.GFD_matches_nr.unique():\n",
    "\n",
    "        df_temp_1 = df[df['GFD_matches_nr']==ID]\n",
    "\n",
    "        for ISO3 in df_temp_1.ISO3.unique():\n",
    "\n",
    "            df_temp_2 = df_temp_1[df_temp_1.ISO3 == ISO3]\n",
    "            df_temp_3 = df_temp_2[~(df_temp_2.GID_1.isnull())]\n",
    "\n",
    "            if len(df_temp_3) > 1:\n",
    "\n",
    "                if df_temp_3[df_temp_3.GID_1.duplicated()].empty == False:\n",
    "\n",
    "                    print('provinces duplicate found')\n",
    "\n",
    "                    duplicated_GID_1 = df_temp_3[df_temp_3.GID_1.duplicated()].GID_1.iloc[0]\n",
    "                    df_temp_4 = df_temp_3[df_temp_3.GID_1 == duplicated_GID_1]\n",
    "                    ISO3_temp = df_temp_4.ISO3.iloc[0]            \n",
    "                    GFD_matches_temp = df_temp_4.GFD_matches.max()\n",
    "                    GFD_matching_type_temp = 4\n",
    "                    GFD_matches_nr_temp = ID\n",
    "                    GID_1_temp = duplicated_GID_1\n",
    "                    GID_2_temp = ''\n",
    "\n",
    "                    for i in df_temp_4.GID_2:\n",
    "                        \n",
    "                        if str(i) != 'nan':\n",
    "                            GID_2_temp = GID_2_temp + str(i) + ','\n",
    "\n",
    "                    try:\n",
    "                        if GID_2_temp[-1] == ',':\n",
    "                            GID_2_temp = GID_2_temp[:-1]        \n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    if len(GID_1_temp) > 1:\n",
    "                        GID_1_temp_len = len(GID_1_temp.split(','))\n",
    "                        \n",
    "                    else:\n",
    "                        GID_1_temp_len = np.nan\n",
    "                    \n",
    "                    if len(GID_2_temp) > 1:\n",
    "                        GID_2_temp_len = len(GID_2_temp.split(','))\n",
    "                        \n",
    "                    else:\n",
    "                        GID_2_temp_len = np.nan\n",
    "                        \n",
    "                    df_max = pd.DataFrame(df_temp_2[max_columns].max()).T\n",
    "                    df_mean = pd.DataFrame(df_temp_2[mean_columns].mean()).T\n",
    "                    df_sum = pd.DataFrame(df_temp_2[sum_columns].sum()).T\n",
    "                    row_single = pd.concat([df_sum,df_max,df_mean], axis=1)\n",
    "\n",
    "                    try:\n",
    "                        row_single = row_single.drop(['GID_1'],axis=1)\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        row_single = row_single.drop(['GID_2'],axis=1)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    row_single.insert(0,'ISO3',ISO3_temp)\n",
    "                    row_single.insert(1,'GFD_matches',GFD_matches_temp)\n",
    "                    row_single.insert(2,'GFD_matches_nr',GFD_matches_nr_temp)\n",
    "                    row_single.insert(3,'matching_type',GFD_matching_type_temp)\n",
    "                    row_single.insert(4,'GID_1',GID_1_temp)\n",
    "                    row_single.insert(5,'GID_2',GID_2_temp)\n",
    "                    row_single.insert(6,'num_provinces',GID_1_temp_len)\n",
    "                    row_single.insert(7,'num_districts',GID_2_temp_len)\n",
    "                    row_single['year'] = np.round(df_temp_4.year.mean(),0)\n",
    "                    row_single = row_single.reindex(columns=df.columns)\n",
    "                    df = df.drop(df_temp_4.index.to_list())\n",
    "                    df = df.append(row_single)\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    print('Number of succesfully matched IDMC events:',len(df))\n",
    "    print(\"Number of individual GFD events:\",len(df.GFD_matches_nr.unique()),'\\n\\n') \n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def district_duplicate_merger(df):\n",
    "    \n",
    "    sum_columns = ['displacements',]\n",
    "\n",
    "    mean_columns = ['GFD_matches_time_dif', 'GFD_duration',        \n",
    "                    'pop_density_GHSL', \n",
    "                    'pop_density_GPW',\n",
    "                    'pop_affected_sum_GHSL', \n",
    "                    'pop_affected_sum_GPW','GDP_affected_sum', 'cable_affected_sum', 'plant_affected_sum',\n",
    "                    'power_pole_affected_sum', 'power_tower_affected_sum',\n",
    "                    'line_affected_sum', 'mast_affected_sum',\n",
    "                    'communication_tower_affected_sum', 'doctors_affected_sum',\n",
    "                    'hospital_affected_sum', 'pharmacy_affected_sum',\n",
    "                    'primary_road_affected_sum', 'tertiary_road_affected_sum',\n",
    "                    'reservoir_affected_sum', 'school_affected_sum',\n",
    "                    'university_affected_sum',\n",
    "                    'affected_mean_GHSL','affected_mean_GPW','GDP_affected_mean',\n",
    "                    'education_affected_mean','energy_affected_mean','health_affected_mean',\n",
    "                    'telecommunication_affected_mean','transportation_affected_mean','water_affected_mean',\n",
    "                    'CISI_global_affected_mean', 'cable_affected_mean',\n",
    "                    'plant_affected_mean', 'power_pole_affected_mean',\n",
    "                    'power_tower_affected_mean', 'line_affected_mean', 'mast_affected_mean',\n",
    "                    'communication_tower_affected_mean', 'doctors_affected_mean',\n",
    "                    'hospital_affected_mean', 'pharmacy_affected_mean',\n",
    "                    'primary_road_affected_mean', 'tertiary_road_affected_mean',\n",
    "                    'reservoir_affected_mean', 'school_affected_mean',\n",
    "                    'university_affected_mean', 'GDPpc_mean', 'HDI_mean',\n",
    "                    'urbanization_mean', 'landuse_total_mean', 'elevation_mean','roughness_mean',\n",
    "                    'slope_mean','female_mean',  \n",
    "                    'pop_0_14_mean', 'pop_65_plus_mean', 'FLOPROS_merged_mean',\n",
    "                    'FLOPROS_modeled_mean', 'forest_cover_mean']\n",
    "\n",
    "    max_columns = []\n",
    "\n",
    "    for ID in df.GFD_matches_nr.unique():\n",
    "\n",
    "        df_temp_1 = df[df['GFD_matches_nr']==ID]\n",
    "\n",
    "        for ISO3 in df_temp_1.ISO3.unique():\n",
    "\n",
    "            df_temp_2 = df_temp_1[df_temp_1.ISO3 == ISO3]\n",
    "            df_temp_3 = df_temp_2[~(df_temp_2.GID_2.isnull())]\n",
    "\n",
    "            if len(df_temp_3) > 1:\n",
    "\n",
    "                if df_temp_3[df_temp_3.GID_2.duplicated()].empty == False:\n",
    "\n",
    "                    print('districts duplicate found')\n",
    "\n",
    "                    duplicated_GID_2 = df_temp_3[df_temp_3.GID_2.duplicated()].GID_2.iloc[0]\n",
    "                    df_temp_4 = df_temp_3[df_temp_3.GID_2 == duplicated_GID_2]\n",
    "                    ISO3_temp = df_temp_4.ISO3.iloc[0]            \n",
    "                    GFD_matches_temp = df_temp_4.GFD_matches.max()\n",
    "                    GFD_matching_type_temp = 5\n",
    "                    GFD_matches_nr_temp = ID          \n",
    "                    GID_1_temp = '' \n",
    "                    GID_2_temp = duplicated_GID_2 \n",
    "                    \n",
    "                    for i in df_temp_4.GID_1:\n",
    "                        \n",
    "                        if str(i) != 'nan':\n",
    "                            GID_1_temp = GID_1_temp + str(i) + ','\n",
    "\n",
    "                    try:\n",
    "                        if GID_1_temp[-1] == ',':\n",
    "                            GID_1_temp = GID_1_temp[:-1]        \n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    \n",
    "                    if len(GID_1_temp) > 1:\n",
    "                        GID_1_temp_len = len(GID_1_temp.split(','))\n",
    "                        \n",
    "                    else:\n",
    "                        GID_1_temp_len = np.nan\n",
    "                        \n",
    "                    \n",
    "                    if len(GID_2_temp) > 1:\n",
    "                        GID_2_temp_len = len(GID_2_temp.split(','))\n",
    "                        \n",
    "                    else:\n",
    "                        GID_2_temp_len = np.nan\n",
    "                        \n",
    "                    df_max = pd.DataFrame(df_temp_2[max_columns].max()).T\n",
    "                    df_mean = pd.DataFrame(df_temp_2[mean_columns].mean()).T\n",
    "                    df_sum = pd.DataFrame(df_temp_2[sum_columns].sum()).T\n",
    "                    row_single = pd.concat([df_sum,df_max,df_mean], axis=1)\n",
    "\n",
    "                    try:\n",
    "                        row_single = row_single.drop(['GID_1'],axis=1)\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        row_single = row_single.drop(['GID_2'],axis=1)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    row_single.insert(0,'ISO3',ISO3_temp)\n",
    "                    row_single.insert(1,'GFD_matches',GFD_matches_temp)\n",
    "                    row_single.insert(2,'matching_type',GFD_matching_type_temp)\n",
    "                    row_single.insert(3,'GFD_matches_nr',GFD_matches_nr_temp)\n",
    "                    row_single.insert(4,'GID_1',GID_1_temp)\n",
    "                    row_single.insert(5,'GID_2',GID_2_temp)\n",
    "                    row_single.insert(6,'num_provinces',GID_1_temp_len)\n",
    "                    row_single.insert(7,'num_districts',GID_2_temp_len)\n",
    "                    row_single['year'] = np.round(df_temp_4.year.mean(),0)\n",
    "                    row_single = row_single.reindex(columns=df.columns)\n",
    "                    df = df.drop(df_temp_4.index.to_list())\n",
    "                    df = df.append(row_single)\n",
    "  \n",
    "    df = df.reset_index(drop=True) \n",
    "    print('Number of succesfully matched IDMC events:',len(df))\n",
    "    print(\"Number of individual GFD events:\",len(df.GFD_matches_nr.unique()),'\\n\\n') \n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36866fc2",
   "metadata": {},
   "source": [
    "# Launch (IDMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4797f141",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 14, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0bb604fcd79b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_data_processed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"IDMC_EMDAT_GFD_match/IDMC_GFD_connect_results_FL_merged2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#,sep='delimiter'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m df.rename(columns={'Internal Displacements':'displacements','Year':'year'}, \n\u001b[1;32m      3\u001b[0m                      inplace=True)    \n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ipykernel_py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 14, saw 2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path_data_processed + \"IDMC_EMDAT_GFD_match/IDMC_GFD_connect_results_FL_merged2.csv\") #,sep='delimiter'\n",
    "df.rename(columns={'Internal Displacements':'displacements','Year':'year'}, \n",
    "                     inplace=True)    \n",
    "\n",
    "for i in range(len(df)):    \n",
    "    ID = df.loc[i,'GFD_matches_nr']\n",
    "    \n",
    "    if \"[\" in str(ID) and len(ID) <= 6:        \n",
    "        df.loc[i,'GFD_matches_nr'] = ID.replace('[','').replace(']','')\n",
    "        \n",
    "df = (df.\n",
    "                pipe(drop_columns_rows).\n",
    "                pipe(matches_filter).\n",
    "                pipe(nat_vs_subnat).\n",
    "                pipe(province_duplicate_merger).\n",
    "                pipe(district_duplicate_merger)\n",
    "             )\n",
    "\n",
    "print(\"FINAL:\")\n",
    "print('Number of succesfully matched IDMC events:',len(df))\n",
    "print('Number of events without displacement numbers:',len(df[df.displacements.isnull()]))\n",
    "\n",
    "df.to_csv(path_FLODIS_final + 'FLODIS_displacements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8fa4271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f0065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d47c80ac",
   "metadata": {},
   "source": [
    "# EM-DAT functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a962ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unneccessary rows and columns. \n",
    "# Check for national vs. subnational entries.\n",
    "# Search for entries with the same GFD ID. \n",
    "\n",
    "def drop_columns_rows(df):\n",
    "    \n",
    "    df = df[df.columns.drop(df.filter(regex='Unnamed:'))]     \n",
    "    df = df.drop([\n",
    "       'Start Year', 'Start Mont', 'Start Day', 'End Year', 'End Month',\n",
    "       'End Day'],axis=1)\n",
    "    df = df.replace(-np.inf,np.nan)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def matches_filter(df):\n",
    "    print('Number of EM-DAT flood events (2000-2018):',len(df))\n",
    "    df = df[df.GFD_matches > 0]\n",
    "    print('Number of succesfully matched EM-DAT events:',len(df),'\\n\\n')\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def GDIS_duplicates(df):\n",
    "\n",
    "    sum_columns = ['total_deaths','no_injured','no_affected_EMDAT','no_homeles',\n",
    "                   'total_affected_EMDAT','total_damages_(000_USD)']\n",
    "\n",
    "    mean_columns = [ 'GFD_matches_time_dif', 'GFD_duration',        \n",
    "           'pop_density_GHSL', \n",
    "           'pop_density_GPW','pop_affected_mean_GHSL','pop_affected_mean_GPW','GDP_affected_mean',\n",
    "           'education_affected_mean','energy_affected_mean','health_affected_mean',\n",
    "           'telecommunication_affected_mean','transportation_affected_mean','water_affected_mean',\n",
    "           'CISI_global_affected_mean', 'cable_affected_mean',\n",
    "           'plant_affected_mean', 'power_pole_affected_mean',\n",
    "           'power_tower_affected_mean', 'line_affected_mean', 'mast_affected_mean',\n",
    "           'communication_tower_affected_mean', 'doctors_affected_mean',\n",
    "           'hospital_affected_mean', 'pharmacy_affected_mean',\n",
    "           'primary_road_affected_mean', 'tertiary_road_affected_mean',\n",
    "           'reservoir_affected_mean', 'school_affected_mean',\n",
    "           'university_affected_mean', 'GDPpc_mean', 'HDI_mean',\n",
    "           'urbanization_mean', 'landuse_total_mean', 'elevation_mean','roughness_mean',\n",
    "           'slope_mean','female_mean',               \n",
    "           'pop_0_14_mean', 'pop_65_plus_mean', 'FLOPROS_merged_mean',\n",
    "           'FLOPROS_modeled_mean', 'forest_cover_mean']\n",
    "\n",
    "    max_columns = ['pop_affected_sum_GHSL', \n",
    "                   'pop_affected_sum_GPW','GDP_affected_sum', 'cable_affected_sum', 'plant_affected_sum',\n",
    "                   'power_pole_affected_sum', 'power_tower_affected_sum',\n",
    "                   'line_affected_sum', 'mast_affected_sum',\n",
    "                   'communication_tower_affected_sum', 'doctors_affected_sum',\n",
    "                   'hospital_affected_sum', 'pharmacy_affected_sum',\n",
    "                   'primary_road_affected_sum', 'tertiary_road_affected_sum',\n",
    "                   'reservoir_affected_sum', 'school_affected_sum',\n",
    "                   'university_affected_sum']\n",
    "    \n",
    "    for ID in df.GFD_matches_nr.unique():\n",
    "\n",
    "        df_temp_1 = df[df['GFD_matches_nr']==ID]\n",
    "\n",
    "        for ISO3 in df_temp_1.ISO3.unique():\n",
    "\n",
    "            df_temp_2 = df_temp_1[df_temp_1.ISO3 == ISO3]\n",
    "\n",
    "            if len(df_temp_2) > 1: \n",
    "                \n",
    "                print(ISO3)\n",
    "                print(ID)\n",
    "                ISO3_temp = df_temp_2.ISO3.iloc[0]\n",
    "                GFD_matches_temp = df_temp_2.GFD_matches.max()\n",
    "                GFD_matching_type_temp = 3\n",
    "                print(df_temp_2.GFD_matches_nr)\n",
    "                print(len(df_temp_2.GFD_matches_nr))\n",
    "\n",
    "                GFD_matches_nr_temp = ID\n",
    "                print(\"New nr:\",GFD_matches_nr_temp)\n",
    "                disasterno_temp = ''\n",
    "                \n",
    "                for i in df_temp_2.disasterno:\n",
    "\n",
    "                    if str(i) != 'nan':\n",
    "                        disasterno_temp = disasterno_temp + str(i) + ','\n",
    "\n",
    "                try:\n",
    "                    if disasterno_temp[-1] == ',':\n",
    "                        disasterno_temp = disasterno_temp[:-1]        \n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                df_max = pd.DataFrame(df_temp_2[max_columns].max()).T\n",
    "                df_mean = pd.DataFrame(df_temp_2[mean_columns].mean()).T\n",
    "                df_sum = pd.DataFrame(df_temp_2[sum_columns].sum()).T\n",
    "                row_single = pd.concat([df_sum,df_max,df_mean], axis=1)\n",
    "\n",
    "                try:\n",
    "                    row_single = row_single.drop(['disasterno'],axis=1)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                row_single.insert(0,'ISO3',ISO3_temp)\n",
    "                row_single.insert(1,'GFD_matches',GFD_matches_temp)\n",
    "                row_single.insert(2,'GFD_matches_nr',GFD_matches_nr_temp)\n",
    "                row_single.insert(3,'matching_type',GFD_matching_type_temp)\n",
    "                row_single.insert(4,'disasterno',disasterno_temp)\n",
    "                row_single['year'] = np.round(df_temp_2.year.mean(),0)\n",
    "                row_single = row_single.reindex(columns=df.columns)\n",
    "                df = df.drop(df_temp_2.index.to_list())\n",
    "                df = df.append(row_single)\n",
    "\n",
    "                print(row_single.GFD_matches_nr)\n",
    "             \n",
    "    print('Number of succesfully matched EM-DAT events:',len(df))\n",
    "    print(\"Number of individual GFD events:\",len(df.GFD_matches_nr.unique()),'\\n\\n')\n",
    "    df = df.reset_index(drop=True)    \n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01151e47",
   "metadata": {},
   "source": [
    "# Launch (EM-DAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ad81ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of EM-DAT flood events (2000-2018): 2390\n",
      "Number of succesfully matched EM-DAT events: 820 \n",
      "\n",
      "\n",
      "nat. entry > subnat. entry\n",
      "VNM\n",
      "2368\n",
      "1      2368\n",
      "556    2368\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2368\n",
      "0    2368\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "MWI\n",
      "2119\n",
      "3      2119\n",
      "522    2119\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2119\n",
      "0    2119\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "2859\n",
      "6      2859\n",
      "252    2859\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2859\n",
      "0    2859\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "AFG\n",
      "3061\n",
      "12     3061\n",
      "666    3061\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3061\n",
      "0    3061\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "1789\n",
      "14     1789\n",
      "443    1789\n",
      "622    1789\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 1789\n",
      "0    1789\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "MNE\n",
      "3756\n",
      "55     3756\n",
      "211    3756\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3756\n",
      "0    3756\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "2279\n",
      "19     2279\n",
      "361    2279\n",
      "632    2279\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 2279\n",
      "0    2279\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PAK\n",
      "2279\n",
      "453    2279\n",
      "766    2279\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2279\n",
      "0    2279\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "AFG\n",
      "2279\n",
      "493    2279\n",
      "543    2279\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2279\n",
      "0    2279\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "MLI\n",
      "3166\n",
      "375    3166\n",
      "470    3166\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3166\n",
      "0    3166\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "2935\n",
      "25     2935\n",
      "569    2935\n",
      "572    2935\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 2935\n",
      "0    2935\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PAK\n",
      "2935\n",
      "38     2935\n",
      "661    2935\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2935\n",
      "0    2935\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PHL\n",
      "3427\n",
      "26     3427\n",
      "188    3427\n",
      "380    3427\n",
      "634    3427\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "4\n",
      "New nr: 3427\n",
      "0    3427\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "4483\n",
      "27     4483\n",
      "740    4483\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 4483\n",
      "0    4483\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "CHN\n",
      "4483\n",
      "218    4483\n",
      "245    4483\n",
      "260    4483\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 4483\n",
      "0    4483\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "MRT\n",
      "3180\n",
      "590    3180\n",
      "813    3180\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3180\n",
      "0    3180\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "BGD\n",
      "2570\n",
      "36     2570\n",
      "609    2570\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2570\n",
      "0    2570\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "2570\n",
      "170    2570\n",
      "358    2570\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2570\n",
      "0    2570\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PRT\n",
      "2117\n",
      "42     2117\n",
      "190    2117\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2117\n",
      "0    2117\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "BEL\n",
      "2117\n",
      "223    2117\n",
      "283    2117\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2117\n",
      "0    2117\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "3866\n",
      "44     3866\n",
      "280    3866\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3866\n",
      "0    3866\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "CHN\n",
      "[2019, 2023, 2035]\n",
      "56     [2019, 2023, 2035]\n",
      "295    [2019, 2023, 2035]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [2019, 2023, 2035]\n",
      "0    [2019, 2023, 2035]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "VNM\n",
      "[2736, 2748]\n",
      "58     [2736, 2748]\n",
      "687    [2736, 2748]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [2736, 2748]\n",
      "0    [2736, 2748]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "MOZ\n",
      "3242\n",
      "290    3242\n",
      "422    3242\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3242\n",
      "0    3242\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "MWI\n",
      "3242\n",
      "431    3242\n",
      "527    3242\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3242\n",
      "0    3242\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "CHN\n",
      "2515\n",
      "66     2515\n",
      "244    2515\n",
      "353    2515\n",
      "570    2515\n",
      "805    2515\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "5\n",
      "New nr: 2515\n",
      "0    2515\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "ETH\n",
      "3123\n",
      "68     3123\n",
      "350    3123\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3123\n",
      "0    3123\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "RUS\n",
      "2650\n",
      "69     2650\n",
      "279    2650\n",
      "683    2650\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 2650\n",
      "0    2650\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "CHN\n",
      "4146\n",
      "74     4146\n",
      "105    4146\n",
      "537    4146\n",
      "782    4146\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "4\n",
      "New nr: 4146\n",
      "0    4146\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PAK\n",
      "3101\n",
      "76     3101\n",
      "256    3101\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3101\n",
      "0    3101\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "AFG\n",
      "2931\n",
      "83     2931\n",
      "152    2931\n",
      "327    2931\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 2931\n",
      "0    2931\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "2931\n",
      "165    2931\n",
      "732    2931\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2931\n",
      "0    2931\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "NIC\n",
      "3490\n",
      "217    3490\n",
      "703    3490\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3490\n",
      "0    3490\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "ROU\n",
      "2692\n",
      "146    2692\n",
      "532    2692\n",
      "757    2692\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 2692\n",
      "0    2692\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "BGR\n",
      "2692\n",
      "258    2692\n",
      "637    2692\n",
      "715    2692\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 2692\n",
      "0    2692\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "CHN\n",
      "2684\n",
      "97     2684\n",
      "567    2684\n",
      "781    2684\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 2684\n",
      "0    2684\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "[3674, 3679]\n",
      "110    [3674, 3679]\n",
      "403    [3674, 3679]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [3674, 3679]\n",
      "0    [3674, 3679]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "2680\n",
      "115    2680\n",
      "786    2680\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2680\n",
      "0    2680\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IDN\n",
      "2403\n",
      "116    2403\n",
      "795    2403\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2403\n",
      "0    2403\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "[4507, 4508]\n",
      "119    [4507, 4508]\n",
      "515    [4507, 4508]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [4507, 4508]\n",
      "0    [4507, 4508]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "CHN\n",
      "4156\n",
      "121    4156\n",
      "733    4156\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 4156\n",
      "0    4156\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PHL\n",
      "3777\n",
      "127    3777\n",
      "201    3777\n",
      "549    3777\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 3777\n",
      "0    3777\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PAN\n",
      "3750\n",
      "129    3750\n",
      "440    3750\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3750\n",
      "0    3750\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "RUS\n",
      "3916\n",
      "135    3916\n",
      "340    3916\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3916\n",
      "0    3916\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PHL\n",
      "3884\n",
      "138    3884\n",
      "373    3884\n",
      "427    3884\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 3884\n",
      "0    3884\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "THA\n",
      "1781\n",
      "541    1781\n",
      "668    1781\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 1781\n",
      "0    1781\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "CHN\n",
      "[3084, 3094]\n",
      "142    [3084, 3094]\n",
      "647    [3084, 3094]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [3084, 3094]\n",
      "0    [3084, 3094]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "BOL\n",
      "2120\n",
      "148    2120\n",
      "437    2120\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2120\n",
      "0    2120\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "1791\n",
      "150    1791\n",
      "509    1791\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 1791\n",
      "0    1791\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "MYS\n",
      "2370\n",
      "151    2370\n",
      "754    2370\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2370\n",
      "0    2370\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "THA\n",
      "2370\n",
      "204    2370\n",
      "812    2370\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2370\n",
      "0    2370\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "VNM\n",
      "[2948, 2949, 2951]\n",
      "153    [2948, 2949, 2951]\n",
      "332    [2948, 2949, 2951]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [2948, 2949, 2951]\n",
      "0    [2948, 2949, 2951]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "4378\n",
      "156    4378\n",
      "186    4378\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 4378\n",
      "0    4378\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "USA\n",
      "3083\n",
      "160    3083\n",
      "365    3083\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3083\n",
      "0    3083\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PHL\n",
      "3900\n",
      "162    3900\n",
      "312    3900\n",
      "341    3900\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 3900\n",
      "0    3900\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "GRC\n",
      "2099\n",
      "177    2099\n",
      "224    2099\n",
      "563    2099\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 2099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2099\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "GBR\n",
      "4009\n",
      "181    4009\n",
      "404    4009\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 4009\n",
      "0    4009\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PER\n",
      "4117\n",
      "435    4117\n",
      "441    4117\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 4117\n",
      "0    4117\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IDN\n",
      "2890\n",
      "208    2890\n",
      "769    2890\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2890\n",
      "0    2890\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "[3716, 3717]\n",
      "216    [3716, 3717]\n",
      "253    [3716, 3717]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [3716, 3717]\n",
      "0    [3716, 3717]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "CHN\n",
      "4390\n",
      "225    4390\n",
      "601    4390\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 4390\n",
      "0    4390\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "DOM\n",
      "3915\n",
      "229    3915\n",
      "416    3915\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3915\n",
      "0    3915\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "CHN\n",
      "[4079, 4083]\n",
      "235    [4079, 4083]\n",
      "316    [4079, 4083]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [4079, 4083]\n",
      "0    [4079, 4083]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "[2676, 2680, 2686, 2689, 2690]\n",
      "238    [2676, 2680, 2686, 2689, 2690]\n",
      "459    [2676, 2680, 2686, 2689, 2690]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [2676, 2680, 2686, 2689, 2690]\n",
      "0    [2676, 2680, 2686, 2689, 2690]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IDN\n",
      "3271\n",
      "240    3271\n",
      "524    3271\n",
      "762    3271\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 3271\n",
      "0    3271\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PHL\n",
      "3305\n",
      "247    3305\n",
      "345    3305\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3305\n",
      "0    3305\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "MDG\n",
      "2633\n",
      "265    2633\n",
      "400    2633\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2633\n",
      "0    2633\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "3107\n",
      "271    3107\n",
      "445    3107\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3107\n",
      "0    3107\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "AFG\n",
      "3055\n",
      "293    3055\n",
      "663    3055\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3055\n",
      "0    3055\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "AFG\n",
      "2632\n",
      "287    2632\n",
      "656    2632\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2632\n",
      "0    2632\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IDN\n",
      "2896\n",
      "288    2896\n",
      "814    2896\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2896\n",
      "0    2896\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PHL\n",
      "3656\n",
      "300    3656\n",
      "571    3656\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3656\n",
      "0    3656\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PHL\n",
      "3216\n",
      "305    3216\n",
      "496    3216\n",
      "685    3216\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 3216\n",
      "0    3216\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "AFG\n",
      "2675\n",
      "317    2675\n",
      "482    2675\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2675\n",
      "0    2675\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "GRC\n",
      "2172\n",
      "344    2172\n",
      "808    2172\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2172\n",
      "0    2172\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "4382\n",
      "355    4382\n",
      "456    4382\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 4382\n",
      "0    4382\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "CHN\n",
      "3301\n",
      "376    3301\n",
      "734    3301\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3301\n",
      "0    3301\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "CHN\n",
      "2900\n",
      "377    2900\n",
      "479    2900\n",
      "615    2900\n",
      "742    2900\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "4\n",
      "New nr: 2900\n",
      "0    2900\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PHL\n",
      "3765\n",
      "385    3765\n",
      "778    3765\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3765\n",
      "0    3765\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "[3327, 3338]\n",
      "415    [3327, 3338]\n",
      "554    [3327, 3338]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [3327, 3338]\n",
      "0    [3327, 3338]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "AUS\n",
      "3752\n",
      "429    3752\n",
      "710    3752\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3752\n",
      "0    3752\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "VNM\n",
      "3210\n",
      "434    3210\n",
      "700    3210\n",
      "708    3210\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "3\n",
      "New nr: 3210\n",
      "0    3210\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "SOM\n",
      "2955\n",
      "446    2955\n",
      "564    2955\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2955\n",
      "0    2955\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "AUS\n",
      "[3247, 3252, 3257]\n",
      "451    [3247, 3252, 3257]\n",
      "783    [3247, 3252, 3257]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [3247, 3252, 3257]\n",
      "0    [3247, 3252, 3257]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "ETH\n",
      "2649\n",
      "469    2649\n",
      "723    2649\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2649\n",
      "0    2649\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IDN\n",
      "[3249, 3251]\n",
      "502    [3249, 3251]\n",
      "566    [3249, 3251]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [3249, 3251]\n",
      "0    [3249, 3251]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "MEX\n",
      "2717\n",
      "699    2717\n",
      "717    2717\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2717\n",
      "0    2717\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "BRA\n",
      "3846\n",
      "595    3846\n",
      "738    3846\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3846\n",
      "0    3846\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "PAK\n",
      "3974\n",
      "604    3974\n",
      "631    3974\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3974\n",
      "0    3974\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IDN\n",
      "3141\n",
      "621    3141\n",
      "806    3141\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3141\n",
      "0    3141\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "USA\n",
      "4337\n",
      "627    4337\n",
      "701    4337\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 4337\n",
      "0    4337\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IND\n",
      "[3371, 3382, 3383]\n",
      "630    [3371, 3382, 3383]\n",
      "730    [3371, 3382, 3383]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: [3371, 3382, 3383]\n",
      "0    [3371, 3382, 3383]\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "USA\n",
      "3815\n",
      "633    3815\n",
      "739    3815\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3815\n",
      "0    3815\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "IDN\n",
      "2779\n",
      "658    2779\n",
      "815    2779\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 2779\n",
      "0    2779\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "GBR\n",
      "3099\n",
      "676    3099\n",
      "705    3099\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3099\n",
      "0    3099\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "BRA\n",
      "3256\n",
      "678    3256\n",
      "765    3256\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3256\n",
      "0    3256\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "AUS\n",
      "3615\n",
      "691    3615\n",
      "725    3615\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3615\n",
      "0    3615\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "nat. entry > subnat. entry\n",
      "AUS\n",
      "3894\n",
      "698    3894\n",
      "741    3894\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "2\n",
      "New nr: 3894\n",
      "0    3894\n",
      "Name: DFO_matches_nr, dtype: object\n",
      "Number of succesfully matched EM-DAT events: 697\n",
      "Number of individual DFO events: 519 \n",
      "\n",
      "\n",
      "FINAL:\n",
      "Number of succesfully matched EM-DAT events: 697\n",
      "Number of events without fatalities and damages numbers: 114\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path_data_processed + \"IDMC_EMDAT_GFD_match/EMDAT_GFD_connect_results_FL_merged.csv\")\n",
    "df.rename(columns={'iso3':'ISO3','Total Deat':'total_deaths', 'No Injured':'no_injured', \n",
    "                   'No Affecte':'no_affected_EMDAT', 'No Homeles':'no_homeles','Total Affe':'total_affected_EMDAT',\n",
    "                   'Total Dama':'total_damages_(000_USD)',}, \n",
    "                     inplace=True)  \n",
    "\n",
    "for i in range(len(df)):    \n",
    "    ID = df.loc[i,'GFD_matches_nr']\n",
    "    \n",
    "    if \"[\" in str(ID) and len(ID) <= 6:        \n",
    "        df.loc[i,'GFD_matches_nr'] = ID.replace('[','').replace(']','')\n",
    " \n",
    "df = (df.\n",
    "                pipe(drop_columns_rows).\n",
    "                pipe(matches_filter).\n",
    "                pipe(GDIS_duplicates)\n",
    "             )\n",
    "\n",
    "print(\"FINAL:\")\n",
    "print('Number of succesfully matched EM-DAT events:',len(df))\n",
    "print('Number of events without fatalities and damages numbers:',len(df[df['total_damages_(000_USD)'].isnull() & df.total_deaths.isnull()]))\n",
    "\n",
    "df.to_csv(path_FLODIS_final + 'FLODIS_fatalities_damages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9c16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
