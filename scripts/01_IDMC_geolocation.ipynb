{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDMC geolocation\n",
    "Script to extract sub-national information out of IDMC entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from rasterstats import zonal_stats\n",
    "import unidecode\n",
    "\n",
    "# Make paths\n",
    "\n",
    "def mkdir(dir):    \n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "        \n",
    "path_run = os.getcwd() + '/'\n",
    "path_data = path_run + 'data/'\n",
    "path_data_creator = mkdir(path_data)\n",
    "path_data_processed = path_run + 'data_processed/'\n",
    "path_data_processed_creator = mkdir(path_data_processed)\n",
    "path_IDMC_geolocation = path_data_processed + 'IDMC_geolocation/'\n",
    "path_IDMC_geolocation_creator = mkdir(path_IDMC_geolocation)\n",
    "\n",
    "# Define decoding which converts diacritics to letters of the alphabet for Modern English (transliteration process)\n",
    "\n",
    "def decoding(x):\n",
    "    \n",
    "    try:\n",
    "        x = unidecode.unidecode(x)\n",
    "    except:\n",
    "        pass\n",
    "    return(x)\n",
    "\n",
    "# Word similarity threshold\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "world_sim_threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract subnational information out of IDMC entries, and assign the corresponding GADM pronvinces and districts.\n",
    "# Load data\n",
    "countries = gpd.read_file(path_data + 'GADM/gadm36_0.shp')\n",
    "\n",
    "provinces = gpd.read_file(path_data + 'GADM/gadm36_1.shp')\n",
    "provinces = pd.DataFrame(provinces)\n",
    "provinces['NAME_1'] = provinces['NAME_1'].apply(lambda x: decoding(x)) \n",
    "provinces['VARNAME_1'] = provinces['VARNAME_1'].apply(lambda x: decoding(x)) \n",
    "provinces_list = provinces['NAME_1']\n",
    "provinces_list_alt = provinces['VARNAME_1']\n",
    "\n",
    "districts = gpd.read_file(path_data + 'GADM/gadm36_2.shp')\n",
    "districts = pd.DataFrame(districts)\n",
    "districts['NAME_1'] = districts['NAME_1'].apply(lambda x: decoding(x)) \n",
    "districts['NAME_2'] = districts['NAME_2'].apply(lambda x: decoding(x)) \n",
    "districts['VARNAME_2'] = districts['VARNAME_2'].apply(lambda x: decoding(x)) \n",
    "districts_list = districts['NAME_2'] \n",
    "districts_list_alt = districts['VARNAME_2'] \n",
    "districts_list_name_1 = districts['NAME_1']\n",
    "districts_list_alt_2 = []\n",
    "\n",
    "subdistricts = gpd.read_file(path_data + 'GADM/gadm36_3.shp')\n",
    "subdistricts = pd.DataFrame(subdistricts)\n",
    "subdistricts['NAME_1'] = subdistricts['NAME_1'].apply(lambda x: decoding(x)) \n",
    "subdistricts['NAME_2'] = subdistricts['NAME_2'].apply(lambda x: decoding(x)) \n",
    "subdistricts['NAME_3'] = subdistricts['NAME_3'].apply(lambda x: decoding(x)) \n",
    "subdistricts['VARNAME_3'] = subdistricts['VARNAME_3'].apply(lambda x: decoding(x)) \n",
    "subdistricts_list = subdistricts['NAME_3'] \n",
    "subdistricts_list_alt = subdistricts['VARNAME_3'] \n",
    "subdistricts_list_name_1 = subdistricts['NAME_1']\n",
    "subdistricts_list_name_2 = subdistricts['NAME_2']\n",
    "subdistricts_list_alt_3 = []\n",
    "\n",
    "# Compute column with alternative names\n",
    "provinces_list_alt_2 = []\n",
    "\n",
    "for i in range(len(provinces_list_alt)):\n",
    "    string = provinces_list_alt[i]\n",
    "    \n",
    "    if string is not None:\n",
    "        str_list = [l.split('-') for l in string.split('|')]\n",
    "        provinces_list_alt_2.append(str_list)\n",
    "        \n",
    "    else:        \n",
    "        provinces_list_alt_2.append('')\n",
    "        \n",
    "provinces['VARNAME_1_2'] = provinces_list_alt_2\n",
    "\n",
    "for i in range(len(districts_list_alt)):\n",
    "    string = districts_list_alt[i]\n",
    "    \n",
    "    if string is not None:\n",
    "        str_list = [l.split('-') for l in string.split('|')]\n",
    "        districts_list_alt_2.append(str_list)\n",
    "        \n",
    "    else:        \n",
    "        districts_list_alt_2.append('')\n",
    "        \n",
    "districts['VARNAME_2_2'] = districts_list_alt_2\n",
    "\n",
    "for i in range(len(subdistricts_list_alt)):\n",
    "    string = subdistricts_list_alt[i]\n",
    "    \n",
    "    if string is not None:\n",
    "        str_list = [l.split('-') for l in string.split('|')]\n",
    "        subdistricts_list_alt_3.append(str_list)\n",
    "        \n",
    "    else:        \n",
    "        subdistricts_list_alt_3.append('')\n",
    "        \n",
    "subdistricts['VARNAME_3_3'] = subdistricts_list_alt_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word similarity score: similar('Tamanrasset','Tamanghasset')\n",
      "2*10/23: 0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "# Word similarity threshold test\n",
    "\n",
    "print(\"word similarity score: similar('Tamanrasset','Tamanghasset')\")\n",
    "print(\"2*10/23:\",2*10/23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare disaster df\n",
    "# Data source: https://www.internal-displacement.org/database/displacement-data (downloaded: 2022-10-17)\n",
    "# Remove 2nd row and save as .csv\n",
    "disaster = pd.read_csv(path_data + 'IDMC/IDMC_Internal_Displacement_Disasters_Events_2008_2021.csv') \n",
    "disaster['countries_forUKonly'] = np.nan\n",
    "disaster['provinces'] = np.nan\n",
    "disaster['GID_1'] = np.nan\n",
    "disaster['districts'] = np.nan\n",
    "disaster['GID_2'] = np.nan\n",
    "disaster['country_only_info'] = np.nan\n",
    "disaster['num_provinces'] = np.nan\n",
    "disaster['num_districts'] = np.nan\n",
    "disaster = disaster.rename(columns={\"Disaster New Displacements\": \"displacements\"})\n",
    "disaster = disaster.rename(columns={\"Event Name\": \"event_name\"})\n",
    "disaster['event_name'] = disaster['event_name'].apply(lambda x: decoding(x)) \n",
    "disaster = disaster.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countries (important for UK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UK countries using GADM provinces \n",
    "for i in range(len(disaster)):  \n",
    "    country = disaster['ISO3'][i]\n",
    "    text = disaster['event_name'][i] \n",
    "    \n",
    "    if country == 'GBR':        \n",
    "        temp_province = ''\n",
    "        temp_GID_1 = ''\n",
    "        \n",
    "        if not pd.isnull(text): # check if event_name is not empty        \n",
    "            provinces_temp = provinces[provinces['GID_0']==country]\n",
    "            \n",
    "            for k in range(len(provinces_temp)):\n",
    "                        \n",
    "                if provinces_temp['NAME_1'].iloc[k]:\n",
    "                                          \n",
    "                    if provinces_temp['NAME_1'].iloc[k] in text:\n",
    "\n",
    "                        if temp_province == '':    \n",
    "                            temp_province = temp_province + provinces_temp['NAME_1'].iloc[k]\n",
    "                            temp_GID_1 = temp_GID_1 + provinces_temp['GID_1'].iloc[k]\n",
    "\n",
    "                        else:                                \n",
    "                            temp_province = temp_province + ',' + provinces_temp['NAME_1'].iloc[k]\n",
    "                            temp_GID_1 = temp_GID_1 + ',' + provinces_temp['GID_1'].iloc[k]\n",
    "                                    \n",
    "        all_provinces = temp_province.split(\",\")\n",
    "        unique_provinces = \",\".join(sorted(set(all_provinces), key=all_provinces.index))        \n",
    "        all_GID_1 = temp_GID_1.split(\",\")\n",
    "        unique_GID_1 = \",\".join(sorted(set(all_GID_1), key=all_GID_1.index))             \n",
    "        disaster.loc[disaster.index==i,'countries_forUKonly'] = unique_provinces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(disaster)):\n",
    "    country = disaster['ISO3'][i]\n",
    "    text = disaster['event_name'][i] \n",
    "    \n",
    "    if country != 'GBR':  # exclude UK, see below next section  \n",
    "        temp_province = ''\n",
    "        temp_GID_1 = ''\n",
    "        \n",
    "        if not pd.isnull(text): # check if event_name is not empty\n",
    "            provinces_temp = provinces[provinces['GID_0']==country]\n",
    "        \n",
    "            for k in range(len(provinces_temp)):  \n",
    "                \n",
    "                if provinces_temp['NAME_1'].iloc[k] in text: # check if province is 100% in IDMC text \n",
    "                               \n",
    "                    if temp_province == '':                     \n",
    "                        temp_province = temp_province + provinces_temp['NAME_1'].iloc[k]\n",
    "                        temp_GID_1 = temp_GID_1 + provinces_temp['GID_1'].iloc[k]            \n",
    "                    \n",
    "                    else: # if not empty, new province is added with \",\"                \n",
    "                        temp_province = temp_province + ',' + provinces_temp['NAME_1'].iloc[k]\n",
    "                        temp_GID_1 = temp_GID_1 + ',' + provinces_temp['GID_1'].iloc[k]                       \n",
    "                        \n",
    "                # check for every word if similarity > world_sim_threshold       \n",
    "                word_list = re.split('\\W+', text)\n",
    "                \n",
    "                for word_single in word_list:\n",
    "                    \n",
    "                    if (similar(word_single,provinces_temp['NAME_1'].iloc[k])) > world_sim_threshold:\n",
    "                        \n",
    "                        if temp_province == '':\n",
    "                            temp_province = temp_province + provinces_temp['NAME_1'].iloc[k]\n",
    "                            temp_GID_1 = temp_GID_1 + provinces_temp['GID_1'].iloc[k]\n",
    "                                       \n",
    "                        else: # if not empty, new province is added with \",\"\n",
    "                            temp_province = temp_province + ',' + provinces_temp['NAME_1'].iloc[k]\n",
    "                            temp_GID_1 = temp_GID_1 + ',' + provinces_temp['GID_1'].iloc[k]\n",
    "                                                 \n",
    "                # check with alt GADM names                \n",
    "                if provinces_temp['VARNAME_1_2'].iloc[k]:               \n",
    "                        \n",
    "                    for l in range(len(provinces_temp['VARNAME_1_2'].iloc[k])):            \n",
    "                        provinces_single = ''.join(provinces_temp['VARNAME_1_2'].iloc[k][l])\n",
    "            \n",
    "                        if provinces_single in text:\n",
    "                            \n",
    "                            if temp_province == '':            \n",
    "                                temp_province = temp_province + provinces_temp.NAME_1.iloc[k] \n",
    "                                temp_GID_1 = temp_GID_1 + provinces_temp.GID_1.iloc[k]\n",
    "            \n",
    "                            else:            \n",
    "                                temp_province = temp_province + ',' + provinces_temp.NAME_1.iloc[k] \n",
    "                                temp_GID_1 = temp_GID_1 + ',' + provinces_temp.GID_1.iloc[k]\n",
    "                                           \n",
    "                    # check if similarity > world_sim_threshold                            \n",
    "                    word_list = re.split('\\W+', text)\n",
    "                    \n",
    "                    for word_single in word_list:\n",
    "                        \n",
    "                        for l in range(len(provinces_temp['VARNAME_1_2'].iloc[k])):            \n",
    "                            provinces_single = ''.join(provinces_temp['VARNAME_1_2'].iloc[k][l])\n",
    "                        \n",
    "                            if similar(word_single,provinces_single) > world_sim_threshold: #and country == provinces['GID_0'].iloc[k]:\n",
    "                                \n",
    "                                if temp_province == '':            \n",
    "                                    temp_province = temp_province + provinces_temp.NAME_1.iloc[k]\n",
    "                                    temp_GID_1 = temp_GID_1 + provinces_temp.GID_1.iloc[k]\n",
    "            \n",
    "                                else: # if not empty, new province is added with \",\"            \n",
    "                                    temp_province = temp_province + ',' + provinces_temp.NAME_1.iloc[k]\n",
    "                                    temp_GID_1 = temp_GID_1 + ',' + provinces_temp.GID_1.iloc[k]\n",
    "                                    \n",
    "        else:            \n",
    "            disaster.loc[disaster.index==i,'country_only_info'] = country\n",
    "    \n",
    "        all_provinces = temp_province.split(\",\")\n",
    "        unique_provinces = \",\".join(sorted(set(all_provinces), key=all_provinces.index))        \n",
    "        all_GID_1 = temp_GID_1.split(\",\")\n",
    "        unique_GID_1 = \",\".join(sorted(set(all_GID_1), key=all_GID_1.index))     \n",
    "        disaster.loc[disaster.index==i,'provinces'] = unique_provinces\n",
    "        disaster.loc[disaster.index==i,'GID_1'] = unique_GID_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UK provinces using GADM districts \n",
    "for i in range(len(disaster)):  \n",
    "    country = disaster['ISO3'][i]\n",
    "    text = disaster['event_name'][i] \n",
    "    \n",
    "    if country == 'GBR':        \n",
    "        temp_district = ''\n",
    "        temp_GID_2 = ''\n",
    "        \n",
    "        if not pd.isnull(text): # check if event_name is not empty        \n",
    "            districts_temp = districts[districts['GID_0']==country]\n",
    "\n",
    "            for k in range(len(districts_temp)):\n",
    "                        \n",
    "                if districts_temp['NAME_2'].iloc[k]:\n",
    "                                    \n",
    "                    if districts_temp['NAME_2'].iloc[k] != country:                                 \n",
    "                        \n",
    "                        if districts_temp['NAME_2'].iloc[k] in text:\n",
    "                                                  \n",
    "                            if temp_district == '':    \n",
    "                                temp_district = temp_district + districts_temp['NAME_2'].iloc[k]\n",
    "                                temp_GID_2 = temp_GID_2 + districts_temp['GID_2'].iloc[k]\n",
    "                                \n",
    "                            else:                                \n",
    "                                temp_district = temp_district + ',' + districts_temp['NAME_2'].iloc[k]\n",
    "                                temp_GID_2 = temp_GID_2 + ',' + districts_temp['GID_2'].iloc[k]\n",
    "                                    \n",
    "                        # check if similarity > world_sim_threshold                         \n",
    "                        word_list = re.split('\\W+', text)\n",
    "        \n",
    "                        for word_single in word_list:        \n",
    "                            if (similar(word_single,districts_temp['NAME_2'].iloc[k])) > world_sim_threshold:\n",
    "                                                       \n",
    "                                if temp_district == '':        \n",
    "                                    temp_district = temp_district + districts_temp['NAME_2'].iloc[k]\n",
    "                                    temp_GID_2 = temp_GID_2 + districts_temp['GID_2'].iloc[k]\n",
    "                                    \n",
    "                                else:                                    \n",
    "                                    temp_district = temp_district + ',' + districts_temp['NAME_2'].iloc[k]\n",
    "                                    temp_GID_2 = temp_GID_2 + ',' + districts_temp['GID_2'].iloc[k]\n",
    "                                                   \n",
    "                            # Varname                                \n",
    "                            for l in range(len(districts_temp['VARNAME_2_2'].iloc[k])):        \n",
    "                                districts_single = ''.join(districts_temp['VARNAME_2_2'].iloc[k][l])\n",
    "        \n",
    "                                if districts_single in text:                        \n",
    "        \n",
    "                                    if temp_district == '':        \n",
    "                                        temp_district = temp_district + districts_temp['NAME_2'].iloc[k]\n",
    "                                        temp_GID_2 = temp_GID_2 + districts_temp['GID_2'].iloc[k]\n",
    "        \n",
    "                                    else:        \n",
    "                                        temp_district = temp_district + ',' + districts_temp['NAME_2'].iloc[k]\n",
    "                                        temp_GID_2 = temp_GID_2 + ',' + districts_temp['GID_2'].iloc[k]  \n",
    "                                        \n",
    "                            # check if similarity > world_sim_threshold                        \n",
    "                            word_list = re.split('\\W+', text)\n",
    "                            \n",
    "                            for word_single in word_list:\n",
    "        \n",
    "                                for l in range(len(districts_temp['VARNAME_2_2'].iloc[k])):        \n",
    "                                    districts_single = ''.join(districts_temp['VARNAME_2_2'].iloc[k][l])\n",
    "        \n",
    "                                    if (similar(word_single,districts_single)) > world_sim_threshold:\n",
    "                                        \n",
    "                                        if temp_district == '':        \n",
    "                                            temp_district = temp_district + districts_temp['NAME_2'].iloc[k]\n",
    "                                            temp_GID_2 = temp_GID_2 + districts_temp['GID_2'].iloc[k]\n",
    "        \n",
    "                                        else:        \n",
    "                                            temp_district = temp_district + ',' + districts_temp['NAME_2'].iloc[k]\n",
    "                                            temp_GID_2 = temp_GID_2 + ',' + districts_temp['GID_2'].iloc[k]\n",
    "                                        \n",
    "        else:            \n",
    "            disaster.loc[disaster.index==i,'country_only_info'] = country\n",
    "    \n",
    "        all_districts = temp_district.split(\",\")\n",
    "        unique_districts = \",\".join(sorted(set(all_districts), key=all_districts.index))        \n",
    "        all_GID_2 = temp_GID_2.split(\",\")\n",
    "        unique_GID_2 = \",\".join(sorted(set(all_GID_2), key=all_GID_2.index))             \n",
    "        disaster.loc[disaster.index==i,'provinces'] = unique_districts\n",
    "        disaster.loc[disaster.index==i,'GID_1'] = unique_GID_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(disaster)):\n",
    "    country = disaster['ISO3'][i]\n",
    "    text = disaster['event_name'][i] \n",
    "    \n",
    "    if country != 'GBR':    \n",
    "        temp_district = ''\n",
    "        temp_GID_2 = ''\n",
    "        \n",
    "        if not pd.isnull(text): # check if event_name is not empty \n",
    "            districts_temp = districts[districts['GID_0']==country]\n",
    "        \n",
    "            for k in range(len(districts_temp)):\n",
    "                \n",
    "                if districts_temp['NAME_2'].iloc[k]:\n",
    "                         \n",
    "                    if districts_temp['NAME_2'].iloc[k] in text : # check if district is 100% in IDMC text \n",
    "\n",
    "                        if temp_district == '':\n",
    "                            temp_district = temp_district + districts_temp['NAME_2'].iloc[k]\n",
    "                            temp_GID_2 = temp_GID_2 + districts_temp['GID_2'].iloc[k]            \n",
    "\n",
    "                        else: # if not empty, new district is added with \",\"\n",
    "                            temp_district = temp_district + ',' + districts_temp['NAME_2'].iloc[k]\n",
    "                            temp_GID_2 = temp_GID_2 + ',' + districts_temp['GID_2'].iloc[k]                       \n",
    "\n",
    "                    # check for every word if similarity > world_sim_threshold\n",
    "                    word_list = re.split('\\W+', text)\n",
    "\n",
    "                    for word_single in word_list:\n",
    "\n",
    "                        if (similar(word_single,districts_temp['NAME_2'].iloc[k])) > world_sim_threshold:\n",
    "\n",
    "                            if temp_district == '':\n",
    "                                temp_district = temp_district + districts_temp['NAME_2'].iloc[k]\n",
    "                                temp_GID_2 = temp_GID_2 + districts_temp['GID_2'].iloc[k]\n",
    "\n",
    "                            else: # if not empty, new district is added with \",\"\n",
    "                                temp_district = temp_district + ',' + districts_temp['NAME_2'].iloc[k]\n",
    "                                temp_GID_2 = temp_GID_2 + ',' + districts_temp['GID_2'].iloc[k]\n",
    "\n",
    "                    # check with alt GADM names\n",
    "\n",
    "                    if districts_temp['VARNAME_2_2'].iloc[k]:               \n",
    "\n",
    "                        for l in range(len(districts_temp['VARNAME_2_2'].iloc[k])):\n",
    "                            districts_single = ''.join(districts_temp['VARNAME_2_2'].iloc[k][l])\n",
    "\n",
    "                            if districts_single in text:\n",
    "\n",
    "                                if temp_district == '':\n",
    "                                    temp_district = temp_district + districts_temp.NAME_2.iloc[k] \n",
    "                                    temp_GID_2 = temp_GID_2 + districts_temp.GID_2.iloc[k]\n",
    "\n",
    "                                else:\n",
    "                                    temp_district = temp_district + ',' + districts_temp.NAME_2.iloc[k] \n",
    "                                    temp_GID_2 = temp_GID_2 + ',' + districts_temp.GID_2.iloc[k]\n",
    "\n",
    "                        # check if similarity > world_sim_threshold\n",
    "                        word_list = re.split('\\W+', text)\n",
    "\n",
    "                        for word_single in word_list:\n",
    "\n",
    "                            for l in range(len(districts_temp['VARNAME_2_2'].iloc[k])):\n",
    "                                districts_single = ''.join(districts_temp['VARNAME_2_2'].iloc[k][l])\n",
    "\n",
    "                                if similar(word_single,districts_single) > world_sim_threshold: #and country == districts['GID_0'].iloc[k]:\n",
    "\n",
    "                                    if temp_district == '':\n",
    "                                        temp_district = temp_district + districts_temp.NAME_2.iloc[k]\n",
    "                                        temp_GID_2 = temp_GID_2 + districts_temp.GID_2.iloc[k]\n",
    "\n",
    "                                    else: # if not empty, new district is added with \",\"\n",
    "                                        temp_district = temp_district + ',' + districts_temp.NAME_2.iloc[k]\n",
    "                                        temp_GID_2 = temp_GID_2 + ',' + districts_temp.GID_2.iloc[k]\n",
    "                                    \n",
    "        else:            \n",
    "            disaster.loc[disaster.index==i,'country_only_info'] = country\n",
    "    \n",
    "        all_districts = temp_district.split(\",\")\n",
    "        unique_districts = \",\".join(sorted(set(all_districts), key=all_districts.index))        \n",
    "        all_GID_2 = temp_GID_2.split(\",\")\n",
    "        unique_GID_2 = \",\".join(sorted(set(all_GID_2), key=all_GID_2.index))      \n",
    "        disaster.loc[disaster.index==i,'districts'] = unique_districts\n",
    "        disaster.loc[disaster.index==i,'GID_2'] = unique_GID_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UK districts using GADM subdistricts\n",
    "for i in range(len(disaster)):  \n",
    "    country = disaster['ISO3'][i]\n",
    "    text = disaster['event_name'][i] \n",
    "    \n",
    "    if country == 'GBR':        \n",
    "        temp_subdistrict = ''\n",
    "        temp_GID_3 = ''\n",
    "        \n",
    "        if not pd.isnull(text): # check if event_name is not empty        \n",
    "            subdistricts_temp = subdistricts[subdistricts['GID_0']==country]\n",
    "\n",
    "            for k in range(len(subdistricts_temp)):\n",
    "                        \n",
    "                if subdistricts_temp['NAME_3'].iloc[k]:\n",
    "                                    \n",
    "                    if subdistricts_temp['NAME_3'].iloc[k] != country:                                 \n",
    "                        \n",
    "                        if subdistricts_temp['NAME_3'].iloc[k] in text:\n",
    "                                                  \n",
    "                            if temp_subdistrict == '':    \n",
    "                                temp_subdistrict = temp_subdistrict + subdistricts_temp['NAME_3'].iloc[k]\n",
    "                                temp_GID_3 = temp_GID_3 + subdistricts_temp['GID_3'].iloc[k]\n",
    "                                \n",
    "                            else:                                \n",
    "                                temp_subdistrict = temp_subdistrict + ',' + subdistricts_temp['NAME_3'].iloc[k]\n",
    "                                temp_GID_3 = temp_GID_3 + ',' + subdistricts_temp['GID_3'].iloc[k]\n",
    "                                    \n",
    "                        # check if similarity > world_sim_threshold\n",
    "                        word_list = re.split('\\W+', text)\n",
    "        \n",
    "                        for word_single in word_list:\n",
    "        \n",
    "                            if (similar(word_single,subdistricts_temp['NAME_3'].iloc[k])) > world_sim_threshold:\n",
    "                                                       \n",
    "                                if temp_subdistrict == '':        \n",
    "                                    temp_subdistrict = temp_subdistrict + subdistricts_temp['NAME_3'].iloc[k]\n",
    "                                    temp_GID_3 = temp_GID_3 + subdistricts_temp['GID_3'].iloc[k]\n",
    "                                    \n",
    "                                else:                                    \n",
    "                                    temp_subdistrict = temp_subdistrict + ',' + subdistricts_temp['NAME_3'].iloc[k]\n",
    "                                    temp_GID_3 = temp_GID_3 + ',' + subdistricts_temp['GID_3'].iloc[k]\n",
    "                                                   \n",
    "                            # Varname                                \n",
    "                            for l in range(len(subdistricts_temp['VARNAME_3_3'].iloc[k])):        \n",
    "                                subdistricts_single = ''.join(subdistricts_temp['VARNAME_3_3'].iloc[k][l])\n",
    "        \n",
    "                                if subdistricts_single in text:                        \n",
    "        \n",
    "                                    if temp_subdistrict == '':        \n",
    "                                        temp_subdistrict = temp_subdistrict + subdistricts_temp['NAME_3'].iloc[k]\n",
    "                                        temp_GID_3 = temp_GID_3 + subdistricts_temp['GID_3'].iloc[k]\n",
    "        \n",
    "                                    else:        \n",
    "                                        temp_subdistrict = temp_subdistrict + ',' + subdistricts_temp['NAME_3'].iloc[k]\n",
    "                                        temp_GID_3 = temp_GID_3 + ',' + subdistricts_temp['GID_3'].iloc[k]                                                                        \n",
    "                                        \n",
    "                            # check if similarity > world_sim_threshold                        \n",
    "                            word_list = re.split('\\W+', text)\n",
    "        \n",
    "                            for word_single in word_list:\n",
    "        \n",
    "                                for l in range(len(subdistricts_temp['VARNAME_3_3'].iloc[k])):        \n",
    "                                    subdistricts_single = ''.join(subdistricts_temp['VARNAME_3_3'].iloc[k][l])\n",
    "        \n",
    "                                    if (similar(word_single,subdistricts_single)) > world_sim_threshold:\n",
    "                                        \n",
    "                                        if temp_subdistrict == '':        \n",
    "                                            temp_subdistrict = temp_subdistrict + subdistricts_temp['NAME_3'].iloc[k]\n",
    "                                            temp_GID_3 = temp_GID_3 + subdistricts_temp['GID_3'].iloc[k]\n",
    "        \n",
    "                                        else:        \n",
    "                                            temp_subdistrict = temp_subdistrict + ',' + subdistricts_temp['NAME_3'].iloc[k]\n",
    "                                            temp_GID_3 = temp_GID_3 + ',' + subdistricts_temp['GID_3'].iloc[k]                    \n",
    "                  \n",
    "        else:            \n",
    "            disaster.loc[disaster.index==i,'country_only_info'] = country\n",
    "        \n",
    "        all_subdistricts = temp_subdistrict.split(\",\")\n",
    "        unique_subdistricts = \",\".join(sorted(set(all_subdistricts), key=all_subdistricts.index))\n",
    "        all_GID_3 = temp_GID_3.split(\",\")\n",
    "        unique_GID_3 = \",\".join(sorted(set(all_GID_3), key=all_GID_3.index))  \n",
    "        disaster.loc[disaster.index==i,'districts'] = unique_subdistricts\n",
    "        disaster.loc[disaster.index==i,'GID_2'] = unique_GID_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract provinces and districts into single columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of provinces per disaster event to create x columns\n",
    "num_of_provinces_list = []\n",
    "\n",
    "for i in range(len(disaster)):\n",
    "\n",
    "    if disaster.provinces.iloc[i] != '' and type(disaster.provinces.iloc[i]) == str:   \n",
    "        provinces_string = disaster.provinces.iloc[i]\n",
    "        result = [x.strip() for x in provinces_string.split(',')]\n",
    "        num_of_provinces_list.append(len(result))\n",
    "\n",
    "max_number_of_provinces = max(num_of_provinces_list)\n",
    "print(\"Max number of provinces:\",max_number_of_provinces)\n",
    "\n",
    "for i in range(len(disaster)):\n",
    "        \n",
    "    if disaster.provinces.iloc[i] != '' and type(disaster.provinces.iloc[i]) == str:   \n",
    "        provinces_string = disaster.provinces.iloc[i]\n",
    "        result = [x.strip() for x in provinces_string.split(',')]        \n",
    "        disaster.loc[disaster.index==i,'num_provinces'] = len(result)\n",
    "        \n",
    "# Determine the number of districts per disaster event to create x columns\n",
    "num_of_districts_list = []\n",
    "\n",
    "for i in range(len(disaster)):\n",
    "\n",
    "    if disaster.districts.iloc[i] != '' and type(disaster.districts.iloc[i]) == str:   \n",
    "        districts_string = disaster.districts.iloc[i]\n",
    "        result = [x.strip() for x in districts_string.split(',')]\n",
    "        num_of_districts_list.append(len(result))\n",
    "\n",
    "max_number_of_districts = max(num_of_districts_list)\n",
    "print(\"Max number of districts:\",max_number_of_districts)\n",
    "\n",
    "for i in range(len(disaster)):\n",
    "        \n",
    "    if disaster.districts.iloc[i] != '' and type(disaster.districts.iloc[i]) == str:   \n",
    "        districts_string = disaster.districts.iloc[i]\n",
    "        result = [x.strip() for x in districts_string.split(',')]        \n",
    "        disaster.loc[disaster.index==i,'num_districts'] = len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up entries if n > 1\n",
    "\n",
    "disaster_single = pd.DataFrame(columns=disaster.columns)\n",
    "    \n",
    "for i in range(len(disaster)):\n",
    "    \n",
    "    try:       \n",
    "        disaster_names = [x.strip() for x in disaster.provinces.iloc[i].split(',')]\n",
    "        disaster_GID_1s = [x.strip() for x in disaster.GID_1.iloc[i].split(',')]\n",
    "\n",
    "        for j in range(len(disaster_names)):\n",
    "            disaster_single = disaster_single.append(disaster.iloc[i])\n",
    "            disaster_single.loc[disaster_single.index==-1,'province_single'] = disaster_names[j]\n",
    "            disaster_single.loc[disaster_single.index==-1,'GID_1_single'] = disaster_GID_1s[j]\n",
    "\n",
    "    except:        \n",
    "        disaster_single = disaster_single.append(disaster.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster.to_csv(path_IDMC_geolocation + 'IDMC_2008_2021_provinces_districts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster = pd.read_csv(path_IDMC_geolocation + 'IDMC_2008_2021_provinces_districts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length IDMC: 11731\n",
      "Length IDMC with geolocated entries: 7915\n",
      "Length IDMC with provinces: 5893\n",
      "Length IDMC with districts: 5740\n",
      "Length IDMC with provinces and districts: 3718\n",
      "Empty Event Name 1202\n",
      "And Flooding between 2008 and 2018:\n",
      "Length IDMC: 3083\n",
      "Length IDMC with geolocated entries: 1702\n",
      "Length IDMC with provinces: 1157\n",
      "Length IDMC with districts: 1074\n",
      "Length IDMC with provinces and districts: 529\n",
      "Empty Event Name 688\n"
     ]
    }
   ],
   "source": [
    "IDMC = pd.read_csv(path_IDMC_geolocation + 'IDMC_2008_2021_provinces_districts.csv')\n",
    "print(\"Length IDMC:\",len(IDMC))\n",
    "print(\"Length IDMC with geolocated entries:\",len(IDMC[~IDMC.provinces.isnull() | ~IDMC.districts.isnull()]))\n",
    "print(\"Length IDMC with provinces:\",len(IDMC[~IDMC.provinces.isnull()]))\n",
    "print(\"Length IDMC with districts:\",len(IDMC[~IDMC.districts.isnull()]))\n",
    "print(\"Length IDMC with provinces and districts:\",len(IDMC[~IDMC.provinces.isnull() & ~IDMC.districts.isnull()]))\n",
    "print(\"Empty Event Name\",len(IDMC[IDMC['event_name'].isnull()]))\n",
    "print('And Flooding between 2008 and 2018:')\n",
    "IDMC = IDMC[IDMC['Hazard Type']=='Flood']\n",
    "IDMC = IDMC[IDMC.Year <= 2018]\n",
    "print(\"Length IDMC:\",len(IDMC))\n",
    "print(\"Length IDMC with geolocated entries:\",len(IDMC[~IDMC.provinces.isnull() | ~IDMC.districts.isnull()]))\n",
    "print(\"Length IDMC with provinces:\",len(IDMC[~IDMC.provinces.isnull()]))\n",
    "print(\"Length IDMC with districts:\",len(IDMC[~IDMC.districts.isnull()]))\n",
    "print(\"Length IDMC with provinces and districts:\",len(IDMC[~IDMC.provinces.isnull() & ~IDMC.districts.isnull()]))\n",
    "print(\"Empty Event Name\",len(IDMC[IDMC['event_name'].isnull()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
